{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise 7 - Answer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishiganeshv/mapillary_tools/blob/master/Copy_of_Exercise_7_Answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "5e8e66fc-3200-4b42-c6f8-41f38aec9b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-18 19:04:40--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 2a00:1450:400c:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  72.6MB/s    in 1.2s    \n",
            "\n",
            "2019-07-18 19:04:42 (72.6 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 19:04:44.857903 139727241586560 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "84a74068-3a89-4117-eb1a-70b41e7fe6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "61b4734a-02ef-43ac-f27c-c8bd78a27b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 19:05:17.515533 139727241586560 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "ca38da6d-8318-4ad6-f113-631836d33207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-18 19:05:27--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 2a00:1450:400c:c0c::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  97.6MB/s    in 1.5s    \n",
            "\n",
            "2019-07-18 19:05:29 (97.6 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-07-18 19:05:32--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 2a00:1450:400c:c0c::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  45.7MB/s    in 0.2s    \n",
            "\n",
            "2019-07-18 19:05:33 (45.7 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "1b961398-f7a5-4bb6-b297-16f5514cb196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "\n",
        "validation_dir=os.path.join(base_dir,'validation')\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1b590756ab76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidation_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_horses_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'horses'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Directory with our training horse pictures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_humans_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'humans'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Directory with our training humans pictures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_horses_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'horses'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Directory with our validation horse pictures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "088bf234-0fbf-4d30-ea3e-98a83b222b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "a8faaa99-271c-43c9-cfbb-448281f3b41f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 38s - loss: 0.2036 - acc: 0.9215 - val_loss: 8.7573e-04 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "100/100 - 32s - loss: 0.0654 - acc: 0.9742 - val_loss: 0.0161 - val_acc: 0.9919\n",
            "Epoch 3/100\n",
            "100/100 - 32s - loss: 0.0359 - acc: 0.9868 - val_loss: 0.0221 - val_acc: 0.9960\n",
            "Epoch 4/100\n",
            "100/100 - 32s - loss: 0.0375 - acc: 0.9859 - val_loss: 0.0026 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "100/100 - 30s - loss: 0.0379 - acc: 0.9899 - val_loss: 0.0285 - val_acc: 0.9919\n",
            "Epoch 6/100\n",
            "100/100 - 30s - loss: 0.0524 - acc: 0.9863 - val_loss: 0.0514 - val_acc: 0.9919\n",
            "Epoch 7/100\n",
            "100/100 - 31s - loss: 0.0303 - acc: 0.9898 - val_loss: 0.1094 - val_acc: 0.9838\n",
            "Epoch 8/100\n",
            "100/100 - 30s - loss: 0.0120 - acc: 0.9960 - val_loss: 0.1962 - val_acc: 0.9727\n",
            "Epoch 9/100\n",
            "100/100 - 30s - loss: 0.0360 - acc: 0.9899 - val_loss: 0.0681 - val_acc: 0.9889\n",
            "Epoch 10/100\n",
            "100/100 - 30s - loss: 0.0268 - acc: 0.9934 - val_loss: 0.2934 - val_acc: 0.9646\n",
            "Epoch 11/100\n",
            "100/100 - 30s - loss: 0.0256 - acc: 0.9894 - val_loss: 0.2485 - val_acc: 0.9727\n",
            "Epoch 12/100\n",
            "100/100 - 31s - loss: 0.0218 - acc: 0.9934 - val_loss: 0.1436 - val_acc: 0.9838\n",
            "Epoch 13/100\n",
            "100/100 - 30s - loss: 0.0170 - acc: 0.9939 - val_loss: 0.1943 - val_acc: 0.9798\n",
            "Epoch 14/100\n",
            "100/100 - 29s - loss: 0.0313 - acc: 0.9934 - val_loss: 0.0113 - val_acc: 0.9970\n",
            "Epoch 15/100\n",
            "100/100 - 32s - loss: 0.0139 - acc: 0.9949 - val_loss: 0.0794 - val_acc: 0.9889\n",
            "Epoch 16/100\n",
            "100/100 - 31s - loss: 0.0384 - acc: 0.9904 - val_loss: 0.1971 - val_acc: 0.9808\n",
            "Epoch 17/100\n",
            "100/100 - 30s - loss: 0.0227 - acc: 0.9944 - val_loss: 0.3297 - val_acc: 0.9737\n",
            "Epoch 18/100\n",
            "100/100 - 30s - loss: 0.0064 - acc: 0.9975 - val_loss: 0.3025 - val_acc: 0.9676\n",
            "Epoch 19/100\n",
            "100/100 - 30s - loss: 0.0514 - acc: 0.9918 - val_loss: 0.3251 - val_acc: 0.9686\n",
            "Epoch 20/100\n",
            "100/100 - 32s - loss: 0.0255 - acc: 0.9950 - val_loss: 0.3598 - val_acc: 0.9656\n",
            "Epoch 21/100\n",
            "100/100 - 30s - loss: 0.0371 - acc: 0.9913 - val_loss: 0.2503 - val_acc: 0.9727\n",
            "Epoch 22/100\n",
            "100/100 - 31s - loss: 0.0136 - acc: 0.9959 - val_loss: 0.3462 - val_acc: 0.9656\n",
            "Epoch 23/100\n",
            "100/100 - 31s - loss: 0.0147 - acc: 0.9965 - val_loss: 0.1466 - val_acc: 0.9879\n",
            "Epoch 24/100\n",
            "100/100 - 31s - loss: 0.0412 - acc: 0.9924 - val_loss: 0.3694 - val_acc: 0.9605\n",
            "Epoch 25/100\n",
            "100/100 - 31s - loss: 0.0128 - acc: 0.9954 - val_loss: 0.2909 - val_acc: 0.9646\n",
            "Epoch 26/100\n",
            "100/100 - 31s - loss: 0.0151 - acc: 0.9954 - val_loss: 0.1703 - val_acc: 0.9879\n",
            "Epoch 27/100\n",
            "100/100 - 29s - loss: 0.0329 - acc: 0.9939 - val_loss: 0.1216 - val_acc: 0.9879\n",
            "Epoch 28/100\n",
            "100/100 - 32s - loss: 0.0241 - acc: 0.9954 - val_loss: 0.1997 - val_acc: 0.9838\n",
            "Epoch 29/100\n",
            "100/100 - 32s - loss: 0.0071 - acc: 0.9970 - val_loss: 0.2000 - val_acc: 0.9798\n",
            "Epoch 30/100\n",
            "100/100 - 30s - loss: 0.0070 - acc: 0.9985 - val_loss: 0.2407 - val_acc: 0.9767\n",
            "Epoch 31/100\n",
            "100/100 - 30s - loss: 0.0276 - acc: 0.9959 - val_loss: 0.1171 - val_acc: 0.9879\n",
            "Epoch 32/100\n",
            "100/100 - 30s - loss: 0.0182 - acc: 0.9970 - val_loss: 0.4513 - val_acc: 0.9646\n",
            "Epoch 33/100\n",
            "100/100 - 30s - loss: 0.0097 - acc: 0.9980 - val_loss: 0.4617 - val_acc: 0.9626\n",
            "Epoch 34/100\n",
            "100/100 - 31s - loss: 0.0201 - acc: 0.9965 - val_loss: 0.6049 - val_acc: 0.9565\n",
            "Epoch 35/100\n",
            "100/100 - 30s - loss: 0.0417 - acc: 0.9939 - val_loss: 0.3454 - val_acc: 0.9686\n",
            "Epoch 36/100\n",
            "100/100 - 30s - loss: 0.0156 - acc: 0.9959 - val_loss: 0.3040 - val_acc: 0.9727\n",
            "Epoch 37/100\n",
            "100/100 - 30s - loss: 0.0091 - acc: 0.9975 - val_loss: 0.2566 - val_acc: 0.9727\n",
            "Epoch 38/100\n",
            "100/100 - 30s - loss: 0.0212 - acc: 0.9954 - val_loss: 0.6673 - val_acc: 0.9565\n",
            "Epoch 39/100\n",
            "100/100 - 31s - loss: 0.0035 - acc: 0.9985 - val_loss: 0.4135 - val_acc: 0.9656\n",
            "Epoch 40/100\n",
            "100/100 - 30s - loss: 0.0083 - acc: 0.9965 - val_loss: 0.7703 - val_acc: 0.9565\n",
            "Epoch 41/100\n",
            "100/100 - 32s - loss: 0.0177 - acc: 0.9969 - val_loss: 0.8436 - val_acc: 0.9534\n",
            "Epoch 42/100\n",
            "100/100 - 32s - loss: 0.0251 - acc: 0.9949 - val_loss: 0.8609 - val_acc: 0.9504\n",
            "Epoch 43/100\n",
            "100/100 - 31s - loss: 0.0142 - acc: 0.9965 - val_loss: 1.0278 - val_acc: 0.9484\n",
            "Epoch 44/100\n",
            "100/100 - 31s - loss: 0.0101 - acc: 0.9965 - val_loss: 0.5146 - val_acc: 0.9565\n",
            "Epoch 45/100\n",
            "100/100 - 31s - loss: 0.0158 - acc: 0.9970 - val_loss: 0.6162 - val_acc: 0.9575\n",
            "Epoch 46/100\n",
            "100/100 - 31s - loss: 0.0086 - acc: 0.9970 - val_loss: 0.5460 - val_acc: 0.9565\n",
            "Epoch 47/100\n",
            "100/100 - 31s - loss: 0.0177 - acc: 0.9949 - val_loss: 0.2012 - val_acc: 0.9838\n",
            "Epoch 48/100\n",
            "100/100 - 31s - loss: 0.0206 - acc: 0.9980 - val_loss: 0.2629 - val_acc: 0.9686\n",
            "Epoch 49/100\n",
            "100/100 - 31s - loss: 0.0118 - acc: 0.9965 - val_loss: 0.4351 - val_acc: 0.9676\n",
            "Epoch 50/100\n",
            "100/100 - 30s - loss: 0.0179 - acc: 0.9985 - val_loss: 0.5073 - val_acc: 0.9646\n",
            "Epoch 51/100\n",
            "100/100 - 30s - loss: 0.0206 - acc: 0.9965 - val_loss: 0.4058 - val_acc: 0.9727\n",
            "Epoch 52/100\n",
            "100/100 - 30s - loss: 0.0220 - acc: 0.9970 - val_loss: 0.6393 - val_acc: 0.9545\n",
            "Epoch 53/100\n",
            "100/100 - 29s - loss: 0.0143 - acc: 0.9975 - val_loss: 0.7620 - val_acc: 0.9514\n",
            "Epoch 54/100\n",
            "100/100 - 31s - loss: 0.0076 - acc: 0.9975 - val_loss: 0.9253 - val_acc: 0.9534\n",
            "Epoch 55/100\n",
            "100/100 - 31s - loss: 0.0148 - acc: 0.9959 - val_loss: 1.1009 - val_acc: 0.9494\n",
            "Epoch 56/100\n",
            "100/100 - 30s - loss: 0.0140 - acc: 0.9954 - val_loss: 1.7569 - val_acc: 0.9281\n",
            "Epoch 57/100\n",
            "100/100 - 30s - loss: 0.0186 - acc: 0.9959 - val_loss: 0.7016 - val_acc: 0.9555\n",
            "Epoch 58/100\n",
            "100/100 - 31s - loss: 0.0191 - acc: 0.9954 - val_loss: 0.4996 - val_acc: 0.9676\n",
            "Epoch 59/100\n",
            "100/100 - 30s - loss: 0.0136 - acc: 0.9965 - val_loss: 1.5061 - val_acc: 0.9372\n",
            "Epoch 60/100\n",
            "100/100 - 31s - loss: 0.0124 - acc: 0.9955 - val_loss: 0.8971 - val_acc: 0.9504\n",
            "Epoch 61/100\n",
            "100/100 - 30s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.6658 - val_acc: 0.9595\n",
            "Epoch 62/100\n",
            "100/100 - 30s - loss: 0.0047 - acc: 0.9985 - val_loss: 1.1613 - val_acc: 0.9464\n",
            "Epoch 63/100\n",
            "100/100 - 32s - loss: 0.0052 - acc: 0.9985 - val_loss: 0.7241 - val_acc: 0.9575\n",
            "Epoch 64/100\n",
            "100/100 - 31s - loss: 0.0068 - acc: 0.9990 - val_loss: 1.3409 - val_acc: 0.9433\n",
            "Epoch 65/100\n",
            "100/100 - 31s - loss: 0.0087 - acc: 0.9970 - val_loss: 1.0759 - val_acc: 0.9494\n",
            "Epoch 66/100\n",
            "100/100 - 30s - loss: 0.0117 - acc: 0.9975 - val_loss: 0.7043 - val_acc: 0.9585\n",
            "Epoch 67/100\n",
            "100/100 - 32s - loss: 0.0039 - acc: 0.9990 - val_loss: 1.2862 - val_acc: 0.9443\n",
            "Epoch 68/100\n",
            "100/100 - 32s - loss: 0.0115 - acc: 0.9980 - val_loss: 1.2668 - val_acc: 0.9372\n",
            "Epoch 69/100\n",
            "100/100 - 31s - loss: 0.0077 - acc: 0.9975 - val_loss: 1.0368 - val_acc: 0.9524\n",
            "Epoch 70/100\n",
            "100/100 - 31s - loss: 0.0069 - acc: 0.9990 - val_loss: 1.6232 - val_acc: 0.9372\n",
            "Epoch 71/100\n",
            "100/100 - 31s - loss: 0.0194 - acc: 0.9964 - val_loss: 1.9817 - val_acc: 0.9261\n",
            "Epoch 72/100\n",
            "100/100 - 30s - loss: 0.0027 - acc: 0.9985 - val_loss: 1.3339 - val_acc: 0.9453\n",
            "Epoch 73/100\n",
            "100/100 - 30s - loss: 0.0153 - acc: 0.9970 - val_loss: 1.1765 - val_acc: 0.9484\n",
            "Epoch 74/100\n",
            "100/100 - 31s - loss: 0.0156 - acc: 0.9969 - val_loss: 1.5664 - val_acc: 0.9322\n",
            "Epoch 75/100\n",
            "100/100 - 30s - loss: 0.0100 - acc: 0.9959 - val_loss: 1.4025 - val_acc: 0.9433\n",
            "Epoch 76/100\n",
            "100/100 - 31s - loss: 0.0033 - acc: 0.9985 - val_loss: 0.7447 - val_acc: 0.9595\n",
            "Epoch 77/100\n",
            "100/100 - 30s - loss: 0.0201 - acc: 0.9954 - val_loss: 0.6757 - val_acc: 0.9626\n",
            "Epoch 78/100\n",
            "100/100 - 30s - loss: 0.0155 - acc: 0.9965 - val_loss: 1.4392 - val_acc: 0.9302\n",
            "Epoch 79/100\n",
            "100/100 - 30s - loss: 0.0039 - acc: 0.9990 - val_loss: 2.6804 - val_acc: 0.9069\n",
            "Epoch 80/100\n",
            "100/100 - 32s - loss: 0.0277 - acc: 0.9970 - val_loss: 1.2053 - val_acc: 0.9484\n",
            "Epoch 81/100\n",
            "100/100 - 31s - loss: 0.0144 - acc: 0.9975 - val_loss: 1.3416 - val_acc: 0.9413\n",
            "Epoch 82/100\n",
            "100/100 - 31s - loss: 0.0142 - acc: 0.9969 - val_loss: 2.1247 - val_acc: 0.9180\n",
            "Epoch 83/100\n",
            "100/100 - 31s - loss: 0.0130 - acc: 0.9950 - val_loss: 1.7003 - val_acc: 0.9241\n",
            "Epoch 84/100\n",
            "100/100 - 31s - loss: 0.0059 - acc: 0.9985 - val_loss: 1.2281 - val_acc: 0.9494\n",
            "Epoch 85/100\n",
            "100/100 - 31s - loss: 0.0131 - acc: 0.9965 - val_loss: 1.0852 - val_acc: 0.9484\n",
            "Epoch 86/100\n",
            "100/100 - 31s - loss: 0.0154 - acc: 0.9965 - val_loss: 1.0709 - val_acc: 0.9504\n",
            "Epoch 87/100\n",
            "100/100 - 31s - loss: 0.0172 - acc: 0.9954 - val_loss: 1.4182 - val_acc: 0.9453\n",
            "Epoch 88/100\n",
            "100/100 - 31s - loss: 0.0132 - acc: 0.9975 - val_loss: 0.8781 - val_acc: 0.9545\n",
            "Epoch 89/100\n",
            "100/100 - 31s - loss: 0.0151 - acc: 0.9959 - val_loss: 0.6971 - val_acc: 0.9565\n",
            "Epoch 90/100\n",
            "100/100 - 31s - loss: 0.0354 - acc: 0.9955 - val_loss: 1.1987 - val_acc: 0.9453\n",
            "Epoch 91/100\n",
            "100/100 - 30s - loss: 0.0116 - acc: 0.9980 - val_loss: 1.1839 - val_acc: 0.9453\n",
            "Epoch 92/100\n",
            "100/100 - 30s - loss: 0.0134 - acc: 0.9965 - val_loss: 2.0011 - val_acc: 0.9211\n",
            "Epoch 93/100\n",
            "100/100 - 32s - loss: 0.0131 - acc: 0.9970 - val_loss: 1.3372 - val_acc: 0.9393\n",
            "Epoch 94/100\n",
            "100/100 - 31s - loss: 0.0033 - acc: 0.9990 - val_loss: 1.4688 - val_acc: 0.9393\n",
            "Epoch 95/100\n",
            "100/100 - 31s - loss: 0.0076 - acc: 0.9985 - val_loss: 1.0455 - val_acc: 0.9433\n",
            "Epoch 96/100\n",
            "100/100 - 30s - loss: 0.0069 - acc: 0.9965 - val_loss: 1.8227 - val_acc: 0.9251\n",
            "Epoch 97/100\n",
            "100/100 - 30s - loss: 0.0174 - acc: 0.9959 - val_loss: 1.7681 - val_acc: 0.9221\n",
            "Epoch 98/100\n",
            "100/100 - 30s - loss: 0.0126 - acc: 0.9970 - val_loss: 1.3591 - val_acc: 0.9362\n",
            "Epoch 99/100\n",
            "100/100 - 30s - loss: 0.0121 - acc: 0.9985 - val_loss: 1.3598 - val_acc: 0.9342\n",
            "Epoch 100/100\n",
            "100/100 - 30s - loss: 0.0344 - acc: 0.9959 - val_loss: 2.8315 - val_acc: 0.8937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "9d138ac2-e422-40a7-dfce-04b6e86a8342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzsnXl8FEXax39PDsINIYEA4RSIGCBc\n4VBAbgUvVmTxdsEVFEXXAxVXvFBX12s9XwUVr1UR8QJvQFzACwIYEJCAgBASrgDhDLme949nKt0z\n6ZnpyRzJzNT38xlmpru6u7oz/Oqpp556ipgZGo1Go4kOYqq7AhqNRqMJHVr0NRqNJorQoq/RaDRR\nhBZ9jUajiSK06Gs0Gk0UoUVfo9Fooggt+lEIEcUS0TEiahPIstUJEXUkooDHHxPRCCLaYfq+mYgG\n2SlbhWu9RkT/rOrxGo0d4qq7AhrvENEx09e6AE4BKHN8v56Z3/XlfMxcBqB+oMtGA8x8eiDOQ0TX\nAbiKmYeYzn1dIM6t0XhCi34YwMwVouuwJK9j5sXuyhNRHDOXhqJuGo039O+xZqHdOxEAET1CRB8Q\n0ftEdBTAVUR0JhH9TESHiSifiJ4nonhH+TgiYiJq5/j+X8f+r4joKBH9RETtfS3r2D+aiHKIqJCI\nXiCiH4hogpt626nj9US0lYgOEdHzpmNjieg/RFRARNsAjPLwfO4lorku214iomccn68jok2O+/nD\nYYW7O1cuEQ1xfK5LRO846rYBQG+XsjOIaJvjvBuI6CLH9m4AXgQwyOE6O2B6tg+ajr/Bce8FRPQp\nEbWw82x8ec6qPkS0mIgOEtEeIrrLdJ37HM/kCBFlEVFLK1caEa1Qf2fH81zmuM5BADOIqBMRLXVc\n44DjuTUyHd/WcY/7HfufI6LajjqfYSrXgohOEFGSu/vVeIGZ9SuMXgB2ABjhsu0RAMUALoQ05HUA\n9AHQD9KbOw1ADoCpjvJxABhAO8f3/wI4ACATQDyADwD8twplmwE4CmCMY9/tAEoATHBzL3bq+BmA\nRgDaATio7h3AVAAbALQCkARgmfycLa9zGoBjAOqZzr0PQKbj+4WOMgRgGICTADIc+0YA2GE6Vy6A\nIY7PTwH4HkAigLYANrqUHQ+gheNvcoWjDimOfdcB+N6lnv8F8KDj8zmOOvYAUBvA/wH4zs6z8fE5\nNwKwF8A/ACQAaAigr2PfPQCyAXRy3EMPAE0AdHR91gBWqL+z495KAUwBEAv5PaYBGA6gluN38gOA\np0z385vjedZzlB/g2DcbwKOm69wB4JPq/n8Yzq9qr4B++fgHcy/633k5bhqADx2frYT8FVPZiwD8\nVoWy1wJYbtpHAPLhRvRt1rG/af/HAKY5Pi+DuLnUvvNchcjl3D8DuMLxeTSAzR7Kfg7gJsdnT6K/\n0/y3AHCjuazFeX8DcL7jszfRfwvAv0z7GkLGcVp5ezY+PuerAaxyU+4PVV+X7XZEf5uXOoxT1wUw\nCMAeALEW5QYA2A6AHN9/BTA20P+vouml3TuRwy7zFyLqTERfOLrrRwDMBJDs4fg9ps8n4Hnw1l3Z\nluZ6sPwvzXV3Ept1tHUtAH96qC8AvAfgcsfnKxzfVT0uIKJfHK6HwxAr29OzUrTwVAcimkBE2Q4X\nxWEAnW2eF5D7qzgfMx8BcAhAqqmMrb+Zl+fcGiLuVnja5w3X32NzIppHRLsddXjTpQ47WIIGnGDm\nHyC9hoFE1BVAGwBfVLFOGmiffiThGq44C2JZdmTmhgDuh1jewSQfYokCAIiI4CxSrvhTx3yIWCi8\nhZTOAzCCiFIh7qf3HHWsA2A+gMcgrpfGAL61WY897upARKcBeBni4khynPd303m9hZfmQVxG6nwN\nIG6k3Tbq5Yqn57wLQAc3x7nbd9xRp7qmbc1dyrje378hUWfdHHWY4FKHtkQU66YebwO4CtIrmcfM\np9yU09hAi37k0gBAIYDjjoGw60Nwzc8B9CKiC4koDuInbhqkOs4DcCsRpToG9e72VJiZ90BcEG9C\nXDtbHLsSIH7m/QDKiOgCiO/Zbh3+SUSNSeYxTDXtqw8Rvv2Q9m8SxNJX7AXQyjyg6sL7AP5ORBlE\nlABplJYzs9uekwc8PecFANoQ0VQiSiCihkTU17HvNQCPEFEHEnoQURNIY7cHEjAQS0STYWqgPNTh\nOIBCImoNcTEpfgJQAOBfJIPjdYhogGn/OxB30BWQBkDjB1r0I5c7APwNMrA6CzLgGlSYeS+ASwE8\nA/lP3AHAWoiFF+g6vgxgCYD1AFZBrHVvvAfx0Ve4dpj5MIDbAHwCGQwdB2m87PAApMexA8BXMAkS\nM68D8AKAlY4ypwP4xXTsIgBbAOwlIrObRh3/NcQN84nj+DYArrRZL1fcPmdmLgQwEsAlkIYoB8Bg\nx+4nAXwKec5HIIOqtR1uu0kA/gkZ1O/ocm9WPACgL6TxWQDgI1MdSgFcAOAMiNW/E/J3UPt3QP7O\np5j5Rx/vXeOCGhzRaAKOo7ueB2AcMy+v7vpowhciehsyOPxgddcl3NGTszQBhYhGQSJlTkJC/kog\n1q5GUyUc4yNjAHSr7rpEAtq9owk0AwFsg/iyzwVwsR5401QVInoMMlfgX8y8s7rrEwlo945Go9FE\nEdrS12g0miiixvn0k5OTuV27dtVdDY1GowkrVq9efYCZPYVIA6iBot+uXTtkZWVVdzU0Go0mrCAi\nb7PSAWj3jkaj0UQVWvQ1Go0mitCir9FoNFGEFn2NRqOJIrToazQaTRThVfSJaA4R7SOi39zsJ8ey\naFuJaB0R9TLt+xsRbXG8/hbIims0Go3Gd+xY+m/Cw/qjkFWIOjlekyHZD+FIwfoAZJm2vgAeIKJE\nfyqr0Wg0Gv/wKvrMvAySctYdYwC8zcLPABqTLOB8LoBFzHyQmQ9BUsl6ajz84uBB4OGHgdWrPZf7\n9lvgN8s+i0aj0UQ+gfDpp8J5abRcxzZ32ytBRJOJKIuIsvbv31+lSsTFAfffD3z1lfsyhw4BY8YA\nd3tcbkOj0WgilxoxkMvMs5k5k5kzmzb1OovYkoYNgdNPB1atcl/mrbeAoiIgKwvQeeY0EUdeHvDa\na8CMGcApD4lNCwrE8vHULS4tBR57DFgZoqzY+/cDDz4oXfZw4uhR4K67gDlzgL17q7s29rCzejqA\ndgB+c7NvFoDLTd83QxaMvhzALHfl3L169+7NVeWqq5hbtrTeV17OfPrpzETMAPPOnVW+TPRy6hTz\nffcxL1kSmuvt28d8++3Mu3eH5nruWL2aedo05pMnq7cezPJDXruW+eGHmf/6V+aLL2a+6CLmXr3k\nh61ef/ublHVl1y7mM86QMjExzFOnMh8+7FzmxAk5J8DcqhVzYaHz/hdeYH7tNft1/ukn5hkzmMvK\n3Je55BK53ogRzCUl9s+teP555sWLfT/OH8rKmMeMcX7u/frJ78UO5eXM//kP89y5AakOgCy2o+e2\nCnkW/fMhS8URgP4AVjq2NwGwHbKYc6LjcxNv1/JH9J99Vu7ISiO++0723XijvH/0UZUvE50cO8Y8\napQ8vORkEWR35R56SF6e/pPbYfJkuV6fPiJEwebrr5nvuou5qMjYtnMnc0qK1OPqq62FNFS8/z5z\n69ZSFyLmtDTmbt2Ye/RgHjKE+bHHmNetY37wQSnz1FPOx2/ezNymDXODBsyffSaCT8TcvLmI8sqV\nzIcOMQ8eLNv/8Q95v/FG4xxvvWUI3F13eX8ehYXMqalS3p24zZ8v+4cNk/dbb/XtuaxdK8fVqcO8\nZo1vx3ri11+ZJ0xgzsuz3n///XLdZ54xGuKWLeXl7hhFSQnz3/8ux9eqxbxpk9/VDZjoQxZozoes\ngJQL4O8AbgBwg2M/AXgJwB+QdSwzTcdeC2Cr4zXRToX8Ef0VK+SOFiyovG/8eObEROaDB5nj4pjv\nuafKlwkdd9zB/NJL1V0L5oIC5jPPFMvw3nuZ4+OZL7vMuUx5OfOHHxqiBMhDNwuoOxYuFEtv/35j\n26ZNzLGxzAMGiPBccUVwBffoURE/QAT08GFpwHr2FJGcNEn2Pf2083FlZSKW997LfNZZzL17y+us\ns5i//TZw9duyRUStVy/m119n3rPHfdmyMuZx4+S5ffYZ8//+JwKdlMTctKmzJZqVxTx8uPxtlQDF\nxUkDwywCDDAvW8a8ahVzQoI8nylTjB5FcbH7ulx/vZy7bVvm006T3qKZggJpVHv2lPPccoucd84c\nqeeMGfIbuOkm5qVLmUtLK1/j0kvlb9S6tbw8PRvF7NnM117LfPy49f6TJ40eUfv2zFu3Ou9XDdWE\nCc6/y+xs5rp1mfv3d//bP3lSemgA8223iTANGOC3kRRQSz+UL39E/9gx+X3dd5/z9vx8+R3fdpt8\n79WLeeTIKl+mSpw4wXzuuT4YIsuXy5+ndevqtS5zc5m7dBExUN2jmTOlbp99Jt+3bJFuOcCckSEC\n8dRTzgLqjjfeEHEHmIcONQTkL3+R/8j79jE/+qjsf/hh5u+/Z54+nXnQIHvd+S1bpC6DB4votG0r\nLovJk53/kz30kFzj7rulUcvIEBcHEfMXX0jZSy6RH9hnn8m2yZOZW7SQ42JjRejPP19eHTrIeT74\noAoP3YWyMuazz2Zu2FDcM3ZQDZZqgOPi5Ee/ebN1+QMHmN9+m/m665yf67FjzO3aMXfqJM+tbVtp\nnMvLjd9Bs2bMHTsyp6eLy+mPP+TYpUtl/+23M3/5pXx+/nnn615zjdRt7Vr5XlIijZCqd0yMNKJ1\n6sj3lBRnq27LFilz113SSNSpIwLq2riY+eILw887cKD17/Oee2T/Y49JY5mSwvzLL8zffCM9H0/C\nrhqEiRMr/9/duFF+JwDzc8/JtjfflO8vvui+zjaIStFnlt7u6NHO25Rm/P67fJ88WRrXUGppdrbU\nwVYPo7xcfrjqh79unf0L7d4tvYPhw+VhHDlS5TpzTo78J69f39mPX1wsotiihbgSEhJEkF54wdkf\n+9//yn/ovn2trUHVMIwYwfx//yefp041umyPPCLlysuZL7/cWcCSkpgbN3YWsZ075T9Us2bySkoy\njunenfnKK0VklB/2wQfluD17mOvVE1FnFgu9fn0p8+STxvmPHpX7VuesX18s6nfeEdE0c+iQNExE\ncm922bhRrIPzzjO6/C++KNfzxY/OLA3EHXeICLn65X3h22+5wn2ixFkxd65Yu1dcwTx2rDyThARx\nfXTsKA3t8ePyNxw6VFyDhYVi7Sr3yIwZzucsKJDfwZw5Ru/v6FHmefPk71i3rmE9TZok18vPN+oD\nyO+xcWOpz5AhzL/9Jvt//1329eghYhsfL43j3r3G9bOypBGfOFG+b9woDZ76u9etK78VdU0r7rtP\nyo4cyfzyy9I43XOPXC8x0dnVVV7OfM45Utc///Ttb2MiakV/4kTpwSpBLy0V3Ro2zCgze7bcuWuP\nzZL//EcsDT9biK+/Nn4DXlmwwPjPoKwNO8yZY/ww27eX91mzKpcrKRELpajI/aDZ6tXyIJOT5T+B\nK+o/BiDWnbvBVvWf0PUennjCOFZZS7ffLtuaN5cG5dgxo/yJE3KOTz4R0di+XeqWliYCu2mT9Ioa\nNhSXwg03yOu556SsmfJycUsAzJ9+KpZbXJxzA7JuHfOrr1b+u//5p/zn/eor766rEyeYL7xQrjNo\nkDRyGzeKpXn99eJf79VLGp+VKw1RaNyYuVEjqdPNN0uDdM451dvjmzXLXs8qN1dcf+p3+N13xr6V\nK7nC7dexo3y+/HJ7LkBFXp4IcKtW8husVUv+zmb++1/5m95yizy/Jk3kWU6fLr+Xpk0Ncf3qK2nM\nmjcXa/DDD8VYatlSfleKnTulZ7Nwob3xpbIy+bt26GA8C+UOshoP275d/s6jR1f57xy1ov/SS3JX\n6m/6+efyfd48o8yaNexxXMmJ3r3ZZ2vbgjfekNNU9DCsfJPs2N61q/ynKC4WK2TgQOcyp05V9kWW\nl4sbpnt3EZbycrFKe/Z0/hEtWSI/LvUjTEhgfuUV53MtXSqulTZtjO6RFZ9+Kt1db1xyiVxHnWvh\nQrGAx493fg4lJSJugLTM3vjf/+Q/84ABYtU3a1bZEnXHyZMyQFy/vjReN91k7zhfKS6Wrqa5h6B6\nCRdfLD0T5WpQPvK9e+V17bVGWT8swGph6VLr/2Djx8s9depU9TGPtWvF2k5IENeOcie5Y98+o5GP\njxf3o5mff5beX8OGxt9h4cKq1c2V8nLmDRvEeFy+3HPZWbOkt1xF337Uiv4vv8hdzZ8v3y+4QBpx\ns3ehuFh+L9OmeTnZgQPGf0jXATwfeewx4/e09c3lYs1ZdddVdIT6DzNjhvywCwqMMhdeKAJvFsxf\nf5XjzK4E5TJZuVK+l5aKFdOuHfO//iWvkSO5wl9eXi6WdEKCDGLZ9R97Iz9f7nfQIOlmN2ggFq7V\nIFphofjB3TWKrqhuW/v20oX2hV27xFdbv75z9z5YbN8u/7Fdewl79og//ccfKx+zerV1Tytc2b9f\n3Cr+hr9+8okxwG+X5cudex6uFBeLazFQgh9iolb0i4qkMZ8+nXnHDvld3Htv5XL9+snYnkfmzeMK\nX+aoUb5XpqxM/OLFxRVBCQDz3NgruMLPbKa0VMSrVy+jtf/pJyn73nvy/fvvjRN98olx7LRpYvWa\nI2AKC8Wqv/Za+a4GjMwWWHGxhCIC0rWMiZEBKlcftb8o11ODBiK0gZwo8fXXVRftbdsCG+anCR1r\n1ji7AKOcqBV9ZtHMESNE7GNirHvGN90kBp7HntSkSdLlu+EGEX6zdVZa6j4S4uuvJQpCxXc3bszj\n2/zE7RoVcAJO8h2p78kgJSAWukL58j/80Pk6yckyCFleLqGTLVuKtT5ggFEmNVV6AFb3UKeOWNut\nWzNnZla+6bIyIzTv3HOD8x+pvFx6FfHxYk1pNJqAEtWiP3myeBNSUsS9Y4XysXucE9G+vfj6lBib\nI1hmzpQWxdXn/cknhkU7frwMMkyYwIPifuSz8T33bfw7Dx5UKhZ5fLwMXirOPVcE3TXS5eqrxWet\nzj1rlgxQAuISWLJEPluFB2ZlcUUopevAmpnycinrKebaX44f990Fo9FobBHVoq/cvIAESlixfr3s\nf/tt6/28dStXxM4eOWKM/jOLJdykiexXwf+KYcMkXMglIqFTp3K+9LxCvunGMqOH8Ze/SMtUUiK9\nBkDixV1RETBJScYA79GjMio8dqyELDVo4D6qoE8frnDfaDSaiMSu6NeIhGuBpk8feW/bFjj3XOsy\nZ5wB1K0LvPkm8Mwz8vrlF1OBxYvlfcQIoEEDoH9/YNEi2fb665IYqmtXOcHJk7J982bgu++AyZOB\nhASn6+XnE5p3aojMPjE4dgzIyQFwzTWSpGnRIuDllyVV6KRJlSt77rlAbKwkynr4YSA+HqhfH5gy\nBfjkE+CDD4BLLgHq1LG+2Vtvlfr8+982np5Go4lo7LQMoXwFwtIvLpZowxde8FzONVdS586mnZdc\n4jwbduZMGRXOz5eTDxxoDKq++aaUue026RG4TNo4elSKPf64Sw+jqEh6DBdeKHHZl17qvrKjRlX2\nx+flSZwy4D2G2p9JWhqNpsaDaHbvMNub31BWJgEuhYXGBLrCQpaB0cREY0YesxFFoybbLFwoFznj\nDIl2OXFCjhk/vtJ1tmyRQ956S05dt67MG2FmIwMcUDl+2Mzx49YDrDfeKBNA7IY4ajSaiMSu6Eek\newcAiLyXiYmRPPwNGwJnnSXb1qxx/HPoEDBypFE4MxNo1AhYuBDo0gU47zy5yA03AD//DPzzn3LM\nDTdUuk5+vrw3by5eml69JKc/AHHxAEC3bsDAge4rW7cuUK9e5e3PPw9s2CAn1mg0Gi9ErOjb4u23\ngfnzAQC9e8umrCwYvvvhw42ycXHG97vvlhYDAK6+Wnzpzz4rq7gMGVLpMnv2yHuLFvKemQmsXSvr\nVKBvX+D668XfbqelciU2ttL4gUaj0bgjekVfWeWTJgFHj6JpUxn4XbWyXJbY6tsXaNbM+ZjrrwfG\njgUuu8zYlphofL/hBkvhNlv6gAw0nzwJbNwIKf/KK8Do0YG/R41Go3EhekX/rbdEeQ8fBmbPBiBi\nnLXshITWTJtW6ZAf6p2DyUkfgePinXdMny7RMxMnWl5qzx7pKCQlyffMTHn3tLSjRqPRBIPoFP3y\ncuD//g8480xg6FCJ1zx1Cpm9Gdv21sfBDn3Eonfh44+BV18Fjh1z2ZGWJm6iRo0sL5efD6SkGB6h\njh1lHMHTEqUajUYTDKJT9BcvBrZsAW66Saz0vDzg3XeRyWJ6rx4z03JgNC9P3n1duzk/3/DnAyL+\nvXubBnODwPffyxBEaan7Mnl5QIcO4sVq1gxITQV++MH+NW64AXjxRb+rqtFoQkh0iv5LLwFNmwLj\nxkmETs+ewBNPoPfCBwEAqxqPsDxMif6hQ75dbs8eZ9EHxJWUnQ0UF/tYd5ssXSrzxPbvd1/mt9+A\nbduAQYPkURQVAU89Ze/85eXAO+8A33wTmPpqNJrQEB2iP2SIiPvatcCffwKffy4DuAkJMpB6113A\n5s1o/NNX6NT0ELLWxlmepqqin59vDOIqMjNF8Nev9/127FBQIO+Fhe7LqB7LI4+It2vSJIlIzc31\nfv68PODECd97PRqNpnqJfNE/fhz43//EpdO7t5GX4frrjTLjxgGnnQYkJyNzSANLtwtz1dw7paVi\nbbta+mowN1guHiX6hw+7L6Puo0kTeZ88WSz4117zfv6cHOdzaDSa8CDyRX/7dnl/5RWJyNm+XSJt\n2rQxysTFAQsWAF9/jcz+cdi1S1LimDlyRCxbwDdLf98+aTBcLf127SSaJ9iib8fST0yU99NOkzbx\n1VeBkhLP59eir9GEJ9Ej+g6/PfLyJEmaK126AL17VyRrcxXj3buNz74InevELAWRWPvVbek3aADU\nqmVsu+EGeUSff+75/GbRZ/avrhqNJnREvuhv2ybv7dvLe1KSpDRwQ8+eIsiuYqxcO4Bvlr7rxCwz\nmZni01dJOgOJHUu/oMBw7SjOPx9o1UqSfnpCiX5pKXD0aNXrqdFoQkvki/727ZKzJjnZVvH69SXt\nsifR92Tpl5dLRIuyfpXou1r6gIh+WZlE8QQau5a+q+ir7M6LFgFbt7o/NifHmHwczi6e3Fxg06bq\nroVGEzqiQ/RPO82nvDa9e0ugjxkl+q1be7b0Fy0CRo0C5s6V78q9487SBwLv4ikuNiaQefPpu4o+\nAFx3nUxTmDXL+riSEulApacb5wlX7r5bhng0mmgh8kV/2zbDtWOTzp3Fh2+eeZuXJxNuW7XyLPob\nN8q7co/k58tAqVVOtNRUmakbaNFXVj7gu6UPAC1bAmPGAG+8IbH7rmzfLj2U/v2N84Qre/fK/ehx\nCU20ENmiz2xY+j6QlibvZvdGXp6IYWKiZ5FTvu7ly2Xyk9XELAWRTNIKdA4es+hXxdIHZFGugoKK\nJKROqHuMBNEvLJSGLZzvQaPxhcgW/f37JU7fR0tfib4SN8AQ/SZNPFv6OTlyfEKCuEesJmaZycwU\nn3KlfD5+YMfSZxahU0ngXBk2THIEvfJK5X2RJPrq+diZkKbRRAK2RJ+IRhHRZiLaSkTTLfa3JaIl\nRLSOiL4nolamfU8Q0QYi2kREzxNVJWl8FVHhmj6KfseO8m4l+nYs/f79gb/+VdL1b9/u3tIHRPSZ\nK48h+IMS/cRE95b+0aMSeePO0o+JkfDNH36oPGs4J0eO69TJ+XrhiHo+WvQ10YJX0SeiWAAvARgN\nIB3A5USU7lLsKQBvM3MGgJkAHnMcexaAAQAyAHQF0AfA4IDV3htK9H1079StKwO2SvTVbFwl+oWF\n4tN25fhxEY+0NBHMI0c8u3eA4KRZViJ82mnuLX3X2bhWTJggPRZXa9/cm6lXL3wtfWZt6WuiDzuW\nfl8AW5l5GzMXA5gLYIxLmXQA3zk+LzXtZwC1AdQCkAAgHoDLXNcgomL027Xz+dC0NEP0DxyQiBXl\n3gGsxVSNAaSlyfKL3brJd0/unZQUWbzl5599rqJblOh36ODe0rcj+klJwPjxkljN7H7askUWCVPH\nh6voFxUZM4+16GuiBTuinwpgl+l7rmObmWwAKgH9xQAaEFESM/8EaQTyHa9vmLlSVDQRTSaiLCLK\n2u8pLaSvbN8uqmq1tqwX0tKAzZudc+6kphopC6z8+qqRSEszls8FPIs+IEvjrlgRuAiSggKgdm3p\nYfgj+oDcw9Gj4qoCnHsz6vhwFX1zw61FXxMtBGogdxqAwUS0FuK+2Q2gjIg6AjgDQCtIQzGMiAa5\nHszMs5k5k5kzmzZtGqAqoUrhmoq0NBGFggJD9M2WvifRV2MCEyZIHLi3lRAHDpQBX+WN8peCArHS\nGzUSF5OVK8qu6J95prwefVRyD5l7M+r4cBV9c4OoRV8TLdgR/d0AWpu+t3Jsq4CZ85h5LDP3BHCv\nY9thiNX/MzMfY+ZjAL4CcGZAam6H7dv9En1AhNws+srStxK6nByJ41cdi7p1gccf9y6sAwbI+4oV\nVapqJcyiD1inSVAuIHfROwoiI2XRs88692YAubdwHchVln7dus65lTSaSMaO6K8C0ImI2hNRLQCX\nAVhgLkBEyUSkznUPgDmOzzshPYA4IoqH9AJCM+m9tBTYudPnQVyFleg3b+7d0lfH+UKXLiLQvqxa\n5Qkl+o0by3er8QfXDJueGDhQJms9/rhRR9WbiQRLPz1dW/qa6MGr6DNzKYCpAL6BCPY8Zt5ARDOJ\n6CJHsSEANhNRDoAUAI86ts8H8AeA9RC/fzYzLwzsLbhh1y7xa1TR0m/XTvLQKNFPTpZoFW+WflVE\nPyZGrP1gWfpWfv2DB6VHYjVT2IrHHhN//osvSmSTylmXlBS+mTZVY9i1q/SGjhyp3vpoNKHAeoko\nF5j5SwBfumy73/R5PkTgXY8rA3C96/aQUMVwTUVcnES/5OQYkTuA+4HcggIRv6qIPiDW9JdfGoLt\nD3YtfW9uJzNnnCE5eWbPdr7HJk3k+Rw/LsnqwgnVGHbpIu+5uUY+IY0mUoncGbmuKZWrgArbVDH6\ngFjGdetWtvRdfd2+ovz6P/770IELAAAgAElEQVRYteMV5pm23ix9X0QfAB58UHoHKhQVMM4Rji4e\ns6UPaBePJjqIXNHfvl1SRbZq5b2sG9LSJCY9N1fCNRWJiZUtfX9Fv08fID7ef7++mjgWaEsfkBDQ\n7GzgoYeMbeoc4TiYW1goPxH1N9Oir4kGIlv027YVP00VSUuTCTx79hiWPmCdfycnRy5VhXlgAIA6\ndWR2rr9+fXNUjidLv6pupA4dgIYNje/hbuk3amQ06Fr0NdFA5Iq+HzH6CrPVbhZ9q/w7OTkyfBAf\nX/XrDRwo6Ris0hnbxUr0A2XpW6EajnAU/cJCeUYJCUCzZlr0NdFB5Iq+HzH6Cnei787Sr6prRzFg\ngCyA4k9+fbPo16olPQhXS1/5/QMh+uFu6SsXWKtWOlZfEx1EpuiXlgL79vnlzwfEh60mWnmy9MvL\nxffvr+ifdZa8++PXd5101bhxZUv/+HGJuAmE6HsKYa3pKEsfkJ+KtvQ10UBkir7yj1Qh544ZIkPI\nXUXfbOnn5sri5v6KftOmEjL43Xfey7rDVfQbNaps6dtNwWCHOnXkFa6ib7b0tehrooHIFv3atf0+\nVVqaTJ5q1szY1qSJ5KE5dUq++xu5Y2bkSGDZMvt+/f/9D3juOeN7QYE0VkrMrCx91TAEQvTVeXyN\n3lm9WtYcuOQSeU2dap0jKJiogVxARP/gQfm7emL3buDOO6UzqdGEI1r0vXDllbJ0oDkIyHWC1rp1\n8n7GGX5fDiNHSvXtungefxy44w5x2QAivomJEooIeLb0/Z0EpqhKKoYZM2QyWk6ODF6/9JIxtSJU\nmC19FcHjza//zjvAU08ZayFrNOGGFn0vXHihpB4w45p/JytLLEVvKZTtMHiwRAB9+633smVlMpmr\nrAz45RfZ5hqKaWXpB9K9AxipGOyybRvwzTfAXXfJqlxzHJmaVI6jUFBWJmkXzJY+4N3FowbZ94Zu\nVQiNJqBo0a8CroOXWVnGClj+Ur++DOjaEf3ffjPyxaj4flfRD7ZPX53HF9GfPVtcZtddJ9/VeEko\nRV9lHjX79AEt+prIJzJF/+RJeQ+S6Jst/cOHJXKnT5/Anf+cc4Bff5UAJE8ooW/WzHAH+WLp28mw\naQdfRP/UKeD114GLLjJcKtUh+uqZKEvfzgSt/fuBP/+Uz1r0NeFKZIp+CC39NWvkc6AsfUBEHwAW\nL/Zc7ocfRKwuuUTcPKWl1pZ+cbHzwPDBg0bUTSBQA7l2Mm1+/LEsP6lWFVN1rFs3tKKvej/K0q9X\nT/6unkTfPH9Ci74mXNGiXwXMA7lqQfPevQN3/p49RUi9uXhWrJAJXQMHyhq269dbW/qAs7VfUBA4\n1w4g5you9h75AgAvvyypHEaMMLYRibVfnZY+4H2CVlaW1DUpSVJzaDThiBb9KqCE9NAhEYL27QMX\nCQNI5M2IESL6yno+dcrZWt+5U5YMGDhQXoDE9x8/XtnSB5z9+ioLZ6CwOyt3wwZg+XLg+uvFp28m\n1KLvaukD0mvyZumffro0WtrS14QrWvSrQGysiOnBgyIEgfTnK0aOlHVzN2wA3n1XcscNHSqzfwHD\nnz9wINCmjSxs8tlnss2bpR+oFAwKu/l33n1XIpMmTqy8r2XL0KZBsLL0O3SQ8NsnnpAZy66sWiVu\nvJQULfqa8EWLfhVp0kQGcHfsCKw/XzFypPF+1VVyKz//DHzwgWz/4QeJ9FG57QcMMAZz7Vj6gXbv\nqPN6YuNGoFMnWYXMFWXph2oFLitL/777gPPOk8Xse/Z0niuRlyeNcJ8+wRH9vXuts6FqNIFGi34V\nSUyU2bBAcES/bVsgI0Nu5eWXga1bge7dgXvvFVfPihXAmWcak8YGDjR6AaG29O2K/rZtYk1b0bKl\nBF2FSvisLP2UFODTT4EFC2SMZNgwYwE2NYirLP19+wI7g3jUKGDatMCdT6Nxhxb9KtKkiREZ2qtX\ncK7x3XfSk7jhBhH3J54QEXr8cRm0Vb58wPmzJ0s/kBk2FXYWUmH2LvpA6Pz6hYUSMWSVCvvCC8XK\nj42VmcOAiH5sLNCjh0zCKy8P3MIxpaUy50Jn+dSEAi36VURF8Jx+urO1GEjMOfEBCeUcMUJWrmJ2\nFvquXY3FTTxZ+ipnUKgt/b17ZZDZneirOPlQib457467+tx6K/DeexKWu2qVrKVbt65Y+kDgXDy7\ndonw64XZNaFAi34VUaIfDNeOJ554QgQ/Nhbo18/YHhsr7h7AWfTr15dIGWXpBzrvDiBCWLu2Z9H/\n4w9598XSLymRFA3BSG5mzrvjjrvvlud0113Os64DLfoq55AWfU0oqPpagjWZoiJRQT+WSvSGsm5D\nLfo9ewI33iji6Jo5+tJLJYzUPOmKyDkVQ6BTMCi8zcpVon/aadb7W7SQd7Pof/EF8Pe/S8rpCy8M\nTD0V3ix9QPbfd59Y/EDwRF89Gy36mlAQuZZ+EK18oPosfUAyUn7ySeXtEycaidfMNGpkuHeCKfr7\n97vfv22bNEDu1hCuV0/qaRb97Gzn90Bix9IHZDxFLcCm/tYqsV6gJmhp0deEEi36VWTwYAmnDORM\n3GDRuLFh6S9dKuLbsWNgr9G3r1jmS5ZY7//jD5lLkJDg/hyuE7RUymr1HkjMq2Z5IiFBGtmhQyV6\nCpCxk4SE4Fj6oQpZ1UQvWvSrSL9+MmM2UPlrgomy9EtKgNdeA0aP9nslyUr85z8yqD1+vHVe/D/+\ncO/PV7hO0AqmpW/HvaMYPVoiqWrVku9EgY3VV6JfVmZEhGk0wUKLfhSgLP0FC2SC0ZQpgb9Gw4Zy\nfmbJoKlSFyvsir6y9I8dk2Pq15dJcHby+viCXfeOOwIl+sxyn6oHpF08mmCjRT8KUJb+yy9LyobR\no4NznQ4dgHnzgN9/B266ydh+9KhMZnI3iKtITZVGqbxc5iEAwLhxIoy//Ra4ehYVSdiqP6G2KSmB\n8ekXFMjzUTOrI130v/sOOP98vdxkdaJFPwpo3Fgs6CVLgMmTjaUUg8GIEXKN+fONyFk1q9WOpV9S\nIkKo/PhXXy3vgfTrW6Vg8JXmzQNj6SvXTs+e8h7Jol9SIr3ML7/0vlaEJnjYEn0iGkVEm4loKxFN\nt9jfloiWENE6IvqeiFqZ9rUhom+JaBMRbSSidoGrvhu06DvRqJFYVnFxEgIZbM47T3zTKneNtxh9\nhTlWPztb6j1kiLh4Ain6VikYfCUlRaKVVOqLqhJNov/667ImMlDZ/acJHV5Fn4hiAbwEYDSAdACX\nE1G6S7GnALzNzBkAZgJ4zLTvbQBPMvMZAPoCCH4br0XfCSVuF18cmHV8vTFkiPM6v1UR/XXrJPdQ\nTIy4PgI5mBsISz8lRQZe/U3FoJ6NigyKVNE/dgx48EFjbokW/erDjqXfF8BWZt7GzMUA5gIY41Im\nHcB3js9L1X5H4xDHzIsAgJmPMXOAh+Qs0KLvRNOm8m5erSqYqHV+Fy2S73/8IXH83kRWiX5uriH6\ngAjiunWBC2cMlKUP+O/X/+MPuW91vkgVw6efFnfYfffJ90i9z3DAjuinAthl+p7r2GYmG8BYx+eL\nATQgoiQAaQAOE9HHRLSWiJ509ByCixZ9J8aNA776SmLNQ8XIkcDateK7tRO5Axizcn/6SURBWb8Z\nGSLUu3a5P9YXAuXTB/z366tno/ImebL0i4oqr3ccDuzdCzz5pPwO1YppkdqjCQcCNZA7DcBgIloL\nYDCA3QDKIGkeBjn29wFwGoAJrgcT0WQiyiKirP2epnXapagoPALoQ0TdupK6lyh01zSv87ttm/fI\nHUDi4Js2Bb7+Wr6bLX0gcH79QFr6/oq+yjzaoIF89ySGd94JDBrk3/Wqg9dfl5Dbf/3LuE9t6Vcf\ndkR/N4DWpu+tHNsqYOY8Zh7LzD0B3OvYdhjSK/jV4RoqBfApgEqJiJl5NjNnMnNmU+WL8Adt6Vc7\nvXqJS+err4A//7Rn6QPi6sjPlwaqa1fZpt4D5dcPlE8f8E/0T56U8YsOHSROPz7es+j/8IMsRGO1\nqpc3mCVpXHXM+N2+XZ5Xp05a9GsCdkR/FYBORNSeiGoBuAzAAnMBIkomInWuewDMMR3bmIiUkg8D\nsNH/antBi361ExsLDB8OfPSRRA75IvqApIlQg34NG0r+m0Ba+jExMvZQVRo1kp6JPz59NXO5Qwdp\n5Bo2dC/6JSWydGZ5ued1fN2xbJms+mVeDSxU5OUZqbO16Fc/XkXfYaFPBfANgE0A5jHzBiKaSUQX\nOYoNAbCZiHIApAB41HFsGcS1s4SI1gMgAK8G/C5c0aJfIzjnHCOtgK+ir1w6CjWYW1UWLzaS0am8\nO/64u4j8j9V3zTzqSfRzcoDiYvm8Y4fzvoMH5f48sXKlvG/ZUqWq+sXu3cbftV49eXZa9KsPW7mH\nmflLAF+6bLvf9Hk+gPlujl0EIMOPOvoGsxb9GoJa5xfwXfQzXH4xGRmS5uHkSd+Ga/78E7jlFjkW\nkEyke/cGZuEbf1MxuIayehJ9s2tr+3bnQfkXXgBmzpS02mpA2BXVYO7cWfX6VpW8PKB/f/lMJD0s\nLfrVR+TNyC0tlT6wFv1qp21bIC1N/NVKzL3hydIvL/ctHcNrrwHp6WIFP/64LIbyzjsyI9Qff74i\nEKLfsKGxoI0n0V+3Tnz+MTGVLf1Nm+TZeBJ01WiEWvSLi2USm/nv36BBzRL9334D3nqrumsROiJP\n9EOwapbGPtdfD1xyiYiVHQYMkMlYZ53lvL1fP5lRPGeO9XGulJXJ4ic9e4oo3n038O9/Sxjpueca\n0UX+4G/+HRWuqdxM3kQ/PV2yo7qKvprl6i6ktbhYngEQetFXz6emiv7u3dIjvfZaQzoinchbOUuL\nfo3i9tt9K9+tm7XvPjVVGpBXXhExP/10z+f5/XdZk/f66yXJnKJrVyMk1F/MqRjsNmpmtm0zEq0B\nIvqbN1uXzc6WGPcdO5xFn9kQfXeCvmmTdIATEkIv+iprqln0GzasGaJ/8iTwl78YDdO2bdKwRjra\n0teEDfffL/78f/7Te9msLHkP5spmzZv7l4ohP995XQN3lv6BAyKeGRmy8phZ9PPzpXED3Au6akSH\nD5feQCjDNq1EvyZY+szApEnyO5kxQ7apxjPS0aKvCRuaNRO//Mcfy6xdT2RlyYChtx6BP6hY/aqE\nUJaVifCZxxbcib4S7e7dRfR37zYiecxC5U70s7PFyh8+XKxbf/MF+UJNFf3Zs4F33wUefhiYNk22\nadEPV7ToRzS33y4W9p13erZYs7JkKcuquF3s0r+/xOq/9JLvxypxdxX9oiJD0BVK9JWlb47VV0LV\ntq1nS79rV2Ot31C6ePLyZAA6OdnYVhNE/+OPgS5dgHvvlUiulBQt+uGLCgzXoh+R1Ksn2Rp/+MEI\nw3SlpAT49dfgL1rfpo0sFvPGGzJTVpGTIwPSVovUK6xSQahwS1dBzM4WUWrWzBButUZBTo781AcM\n8GzpZ2QYYxuhFv0WLZwb35og+uvWyWQ1NYielqZFP3zRln7E8/e/A507A9OnW6/AtGGD/AyCLfqA\nWIoNGkhdAJn4ddFFwI8/Ao895v44q1QQ7pKurVtnhLC2ayfvyq+fkyPpDdq2Feu/rMz52L17Jeld\n9+7VI/rmiVmK6hb9fftk8NY8F0SLfjijRT/iiYsTQf39d+sQzlAM4iqSkkTwFy4Eli4FrrhCQjHP\nPVe2uQuj9GTpm0W/tFQaMSVQrVpJiguz6KeliaCXllYOITW7hpKT5b+FO9EvLZXolXnzbN++V/Ly\nrEX/1KnKbqxQYR4jUaSlSQOpGuNIRou+JiwZM0Zi+R94wIheUWRliQVtdxawv/zjHyLGF14oE7+e\nf17WI2aWCWJWeLL0zVZwTo4IpBKouDgjVr+0VBoYJfpA5UZGTcrKyBBXRps27kU/P1/CO3/80fat\ne8Wd6APVZ+2rZ2IOl01Lk/fqSFMRarToa8ISIsnRvmcP8MwzzvtWrRIrP1SppOvUkTQIal7AlCni\nex81Cnj1VeusmHYtfbOlrlBhm0r4zaLvKujr1skcBzXr15Poq8HhqkQjWXHihNxnTRP9detknMGc\n0FeJfjS4eLToa8KWs86SJSCfeMJYaLuoCFi/PjSuHTMTJsjg8osvGtumTBHreeHCyuXt+vSzsyX6\npXNnY5sSfTWRy5Poq0FcRZs27l1OgRb9/Hx5r07RLyyUnERmsrMrp/lQM6O16IcjWvSjiscekz/5\npEkSyrh+vVjWoRZ9ImmE4kxz3M87D2jdWlw9rihL35wgzUr0N2wQwa9Vy9jWvr0MkKo8RGlpcmyj\nRs6ir9IvmAWuTRsRYyt/eqBF3ypGHwid6OfnyxjFGNPiriUlEmnlmtAvIUEaUy364YgW/aji9NNl\n/dUFC8S/rwZx+/Sp3noBMuA6ebIkfHP1FRcWSvhpfLyxzUr01cpaZtq1k/GCxYuBxET3rpvffxeR\nMwtc69Zy7G6nZZAEJfb5+dZRUb4SStH/7TfnmcpFRcDYsVKH5cuN3o16Jq6WPhA9ETxa9DVhz803\nS8KsRx4Bnn1WfLWtW3s/LhRMmCDvn3/uvP3w4crpnVWueSX6zCJkKkxTob4vXy5CpcYuWrd2Fn2V\nQ79HD2Obp7BNJfrl5f4v+A6EVvRHjZIe0cyZIgFTpgA//yzZVQGZjAVYj5EolOhXx+pioSRyRT8h\noXrroQkZRMD//Z+4V3JyQjuI643UVHH5uC79XFhYOb0zkQiiEv2CAhkcdif6p04ZA5BAZUt/0SIR\nXPN4gDfRV5OorHoCVvzyi/uUGLt3yyC36326m4SmKC8H3nzTfkgnszRSjRtLb69tWzn+gQcku2q3\nbsB8x2of2dniKrNKz5GWJnXyd93jmk5kin5cnLNzVRPxJCTI0oydOwMXXFDdtTEgEvfLgQPO260s\nfcA5/45yV6hZuIrUVHEdAZVFv6BAombKysT9M3KkcwOoekBWor97t7EesR2//pEj8qxvvtl6vwrX\ndG2AvVn6q1fLYjdz53qvAwAcOyb3O20a8O23Mh/h8sslQR8AjBsng+z5+UaKarNbTREtETyRKfra\ntROVNG8uA5c33ljdNXEmObmy6FtZ+oC16Lta+nFxhni7ij4g/uu1a2UZRdd1A+rUEfeXq+iXl4vo\nqxWu7Ij+k0/KfbnrFVjF6APeRV/d/4oV3usAGNE5iYnSyG3YALz3ntFrGTdOegOffGIduaPQoh+u\naNHX1DCsRN+Opa/y67RtW7mcsv6tRH/nTrF4AcnB74pVrP6+fTJ4m5Eh/328iX5ensyPiIsTd4jV\nwK870a9VS17uRP/ECXmviuhbkZ4uPcBZsyqnXzDTurX0GLXohxta9DU1DH8s/cRE68ZBWf8dOxrb\nzKK/aJEM4DZrVvlYq1h9JfKtW4v7yJvoP/igRMHcdptY0a5+cGb3og94zr+jRH/TJntpoFX4q6cl\nMMeN8zyIC4jLrGNHLfrhhxZ9TQ3DVfSZ7fv0XV07iiuvFB92/frGNuU/37hRfNjuloRs00YWjDdH\nqSiRT02VNA+eRH/TJuD11yVCZtAg2aYidRRHj8ogtD+iD9hLCeHN0gdkyU6FO/cOEB1hm1r0NZog\nk5ws/vXycvleVCRWsj+iP3y4+NTNxMeLyL7/vpx/5EjrY1u3lsFPc3IxJfKtWnkX/QcflPDSGTMM\nUXcVfXfhmgq7om/HxWNH9Lt3l/kOzZs7p19wJS1NZjqffrq8zj478tbOjbwQFy36mhpGcrJElxQW\nijB5ckco0Vcx+uee69u12rSREMratYGBA92XAcQNpOqQmyuNRtOmIvp5ee7X/l2zRmYbN21qpHJ2\nHcz1R/RVAr2MDN9E35N7hwh47rnKKRlcufpquZfSUnk+y5dLryiYK7CFGm3pazRBRq0apVw8ysJ2\nZ+kfPSoDqydOVA7X9IYS9LPPdv/fQJUxz2DNzRXXTkyMiH5xceVxCMW+fWIxAyL8sbHBsfRHjpQZ\n1t4s7cOHRdTNKS2sOP984KqrPJfp0gV45x3pLam1cw8e9HxMuBGZol+nTnXXQqOpwFX0vVn6gJFX\nx517xx1K0N358wERtthYyUaq2L3bWKRdvVu5eIqKpCeiBohjY6UBcBV9Zfl7En2r9YABEf3ataXh\nKi42Umu449AheZaBXhpTuYu89Q7MuC5iUxOJTNHXlr6mBuGrpQ8YkSa+iv5pp8m7J9GvX18ie8yu\nk9xce6KvZhabo4JatrQW/QYNnAeazXiz9OvWlRnWgHcXz6FDnv35VaVJE+P8dsjLk56Pu2U8awpa\n9DWaIFMVS1+JvlWMvieuvhr45hvnBUKsGDhQUiiUlMj4gVn0U1Pl3Ur0VQprb6K/datzOKkrdkQ/\nOVni63/4wfO9KEs/0KiGxK5757XXpC5qkZaaihZ9jSbIqCyYvlr6TZp491O7Uq+eZytfMXAgcPKk\nMXO3qMgQ+2bNZNKVP6KvlnF0R4MGEkFkldzs+HERfVXPH34wIp+sOHw4OJa+L+6d0lJg9mz5XNNz\n92jR12iCTP36MgPVF0t/wwbfXTu+MGCAvK9Y4RyuCYifvmVL30S/oEASwAHih9++3bvol5c7h2cq\nTpyQxgsQ0T90SOYGuCNY7p24OKmnHUv/iy/EpUUUIaJPRKOIaDMRbSWi6Rb72xLREiJaR0TfE1Er\nl/0NiSiXiF50PTbgaNHX1DCIxFWhZpcWFoqwKmEzo0T/1Kngin6LFuL/txJ99dkqp46V6Kseglop\na9s2EXRPou8p06Zy7wBAv37yvnq1+3MFy70DSG/LjqX/8svyHM46KwJEn4hiAbwEYDSAdACXE1G6\nS7GnALzNzBkAZgJ4zGX/wwCW+V9dG2jR19RAzLNy1Wxcq/TPZneOr+GavjJwoGfRd2fp16nj3GCp\nCB3VSKgZrd4sfcC76LdoIe/uwkeB4Ll3ADmvN9Hftk3GUSZNkucWiLUIgokdS78vgK3MvI2ZiwHM\nBTDGpUw6gO8cn5ea9xNRbwApAL71v7peYNair6mRmEW/sNDanw84i34wLX1ARH//fuD77yXcUcXe\nA4bou/rc9+0TK9/cYLnOylWi36mT+2vbFf2GDaVX5M7FUlQkr2CKvjf3zqxZUsfrrgNSUmq+pW9n\nRm4qAHN6plwA/VzKZAMYC+A5ABcDaEBESQAOAXgawFUALPL9CUQ0GcBkAGijAo2rggpF0KKvqWEk\nJxtRHYcPu3dHKDEEgi/6yq+/YIFY1OYlKFJTRXxdrWgl+masRL9pU89C7En0zQO5RJ6F104KBn9o\n0qTyeEJRkazNfOyYfH/zTeCii+SZpaTI/IOabHsGKg3DNAAvEtEEiBtnN4AyADcC+JKZc8nDUkbM\nPBvAbADIzMys+mJleqlETQ3FrqUfFyeCd+JE8EW/c2cRtYMHK4d4mmP1XUVfuVwUTZrIQLVZ9D25\ndgDvlr7ZfaTqaIWdFAz+YNXgLF8uyzLWqSMWfq1awO23y76UFHnfu9f3cNtQYce9sxuAecXRVo5t\nFTBzHjOPZeaeAO51bDsM4EwAU4loB8Tvfw0RPR6IiluiRV9TQ1FJ18rKPFv6gOHiCbZoxMQY1r4a\njFW4m6BlZekTOYdtBkL0laUPiOi7S7GsIqGCaekfOuTs5lI+++xsqX9BgZHnSIl+Tfbr2xH9VQA6\nEVF7IqoF4DIATnPOiCiZiNS57gEwBwCY+UpmbsPM7SC9gbeZuVL0T8DQoq+poSQni3AcOuTZ0gdE\nEJOSnF09wUKJVatWztvVd3MED7O16AOG6B89KlE8gRT9pKTqc+8kJkok1cmTxjbls1cCb0aNi9Rk\nv75X0WfmUgBTAXwDYBOAecy8gYhmEtFFjmJDAGwmohzIoO2jQaqvZ7Toa2oo5lm5diz9YLt2FMrS\ndxX9Fi3EgjcvtnLkiMTgexL9LVvke1VFv6REXq6WfnW6d8zXAUTQa9e2bpTN7p2aii2fPjN/CeBL\nl233mz7PBzDfyzneBPCmzzX0BS36mhqKEv29e0XoPFn6t97qPKgaTPr2BW65Bbj4Yuft8fHSEGzb\nZmyzitFXpKbKEo12wjUBIyePq+gri9pX0Q+me0ddR7nA9u4Vi95qmFI9m7AX/bBBi76mhqJSMah1\nbz1Zpt7S/waS+HjJM2+F6ypSnkS/ZUvpCaxZI2LYoYPn68bEyGCtq+irXPquA7lHjkgPID7eubyd\npRL9wSr/zp491q4dQNbYbdzYs09/wgRZyObhhwNWTZ+IrDQMykzQoq+pYShL/48/5N2TpV9TUKKv\nBjG9iT4gMf9t2tjLbm6VXlmlZXC19AFD4M0cOiS9BtfGIFBYZdrcu9e96APSC3Bn6TMD8+cDjzwi\nS05WB5El+trS19RQlOhv3SrvwbJMA0lamgitCjW1I/qrV3t37SisMm1aib7qJVlF8AQzBQNgbel7\nE31PE7QOHzbmIUyZ4j2DaDDQoq/RhIC6dcX6DTdLHzBcPEr0VQNmRom+t5w7ZuyKvrK2rfz6wUzB\nYL62svTLymQWc1VFf+dOeX/2WekRjR3rPFgeCrToazQhIjk5/Cx9wFn0ExNlMpIr5hWy7Iq+WhrS\njK+iH6wMm4oGDWT8QV37wAFp2MwpK1xJSXHv01ei3727zIQ+cQKYHrwgdku06Gs0ISI52bAYw8HS\nb9dOoojMom/l2gFEHNXgqz+WvruBXMC96AezAY2JkfOrv5unGH1F8+ZGKgZXlOi3aQOkpwM9exrZ\nSUOFFn2NJkSY3SLhYOnHxUkUjh3RV7NygdC6d4Jt6avr+yL6nmL1d+6UnpJ6jnXrGg1dqNCir9GE\nCLPoh4OlDziHbXoSfUDi2OPj7aePsCv6jRqJxW01kBtsnz7gnH8nEKLfurWxiLvKsxRKtOhrNCFC\niX7dusELMQw0aWkyy7a83Lvod+8ui57Exto7t13Rj4mxTnxWWirHh9LSV756bz59c1kzO3eKa0dR\nr17oLf3InJyVkFC99SrRF6AAABn2SURBVNBoLFCiHy5WPiCif+qUTCorKPAs+k8/LdEtdmnQQKbW\nlJYaM5CtRB+wnpUb7IlZisREI+rKUwoGhTdLf/hw47u29P2lqEhMKLumhkYTQpToh4M/X6H88z/9\nJBOLPIm+SjNsFyWcKi89YFi9dkQ/2CkYzNc2+/RTUqxTMCjciX5pqeQnam3KWVwdln7kib527Whq\nKOFq6QOyrCLgWfR9xSrp2okT0lF3tds8Wfqh8OkfOiQuLm8TswAjFYOr6OflyTnM7h1l6buuUBZM\ntOhrNCFCzSwNJ0u/RQtJc7B8uXwPpOirxs+cXsE1rbLCk6UfCvdOebk0Tp7y7pixitU3h2sq6tWT\ncxcXB66+3tCir9GEiHC09InE2t+4Ub4HUvSt8tp4En3X6J1QunfU9VSGTW9Yzcq1En11r6F08WjR\n12hCRDj69AHnuPtgiL7Zgncn+klJsvhMaamxLZTuHUBm43pLwaCwSrqmRN/Vpw+EdjBXi75GEyLC\n0dIHDNGPiwtsg6XcXWbRP37ceTauwirTZqgtfRW6ate9YyX6TZoYawkA2tL3n6IiezldNZpqICFB\nwhqvvrq6a+IbSvSbNjUmFQUCJaZmt40n9w7g3EAcOiTRQsG281SjsmmTvNsV/cJC51QMamKWmeqw\n9CMvTl9b+poazO23V3cNfEeJfiBdO4AIXnx8ZfeOJ0vfVfQTEz2HTwYCJfq//y7vdn36gFj7aoby\nrl2VZytrS99ftOhrNAGnUyd5D7ToE1WOyvFm6Zt7BaFIwWC+ti+WvtUC6a6zcQHjXrVPv6po0ddo\nAk7jxhK6aU6fHCjsir6V/z/YGTYVdeqIG0nlILLr3gEM0T9yRBopV9FXvZpQWvravaPRaLyycKH4\n9AONq+h7G8h1Ff1A9z6sUD2SPXtkXKZhQ+/HuObfUQulaEs/0GjR12iCQu/elQUrECQl2bP0GzUS\n8bXy6YcCdR1vKRgUKSkyq3jtWvluFaMPVI+lr0Vfo9FUG3bdO7Gx4soxlw2VTx8wehp2BnEB6RFM\nmAC89pokq7OK0Qe0pe8/WvQ1mrDCPNO2tFTSEViJviqrRP/oUbH0g+FyssJs6dvloYdkbsOMGSL6\nsbEyNmJGT87yFy36Gk1Y0aSJuDZOnZI0y4Bn0VcNxPffS5Kys88OSTWrJPqpqcCttwLvvQd88YV8\nj3MZRVVJgbV7pyowa9HXaMIMc14bq/VxzZj9/99+K43DWWcFv46AUU9fRB8A7r5b6p2dbT0mQiT3\nqy39qqDS1GnR12jCBnNUjrsFVMxlzaI/eHDo1ktSlr5dn76iUSPgvvvks7uB8FCvkxs5oq+XStRo\nwg5z/L1d0f/zT4mZP+ec0NRRXRvw3dIHgClTgEGDnFfMMhPq1bNsiT4RjSKizUS0lYimW+xvS0RL\niGgdEX1PRK0c23sQ0U9EtMGx79JA30AFWvQ1mrDDV0v/8GHg66/l+8iRwa+foio+fUWtWsCyZcC1\n11rvD/XqWV4nZxFRLICXAIwEkAtgFREtYOaNpmJPAXibmd8iomEAHgNwNYATAK5h5i1E1BLAaiL6\nhpkPI9A0aya/Gr1UokYTNpjTK6hJT55Enxn48EOZHZyeHpo6AmKpjx4N9OgR+HPXREu/L4CtzLyN\nmYsBzAUwxqVMOoDvHJ+Xqv3MnMPMWxyf8wDsAxCcICsiY760RqMJC8yWvreBXFV26VJx7QQ70ZqZ\ntm2BL7+0NxvXV0Jt6dsR/VQAu0zfcx3bzGQDGOv4fDGABkSUZC5ARH0B1ALwh+sFiGgyEWURUdb+\n/fvt1l2j0YQ5DRpIGKMd947y/5eXh9a1E2xqoqVvh2kABhPRWgCDAewGUKZ2ElELAO8AmMjM5a4H\nM/NsZs5k5symoZptodFoqh1zpk07Pn3FiBHBr1uoqHE+fYiAmycPt3Jsq8DhuhkLAERUH8Alym9P\nRA0BfAHgXmb+ORCV1mg0kYOvot+zZ2gSrYWKmmjprwLQiYjaE1EtAJcBWGAuQETJRKTOdQ+AOY7t\ntQB8AhnknR+4ams0mkjBruir5SYjybUD1MDJWcxcCmAqgG8AbAIwj5k3ENFMIrrIUWwIgM1ElAMg\nBcCjju3jAZwNYAIR/ep4BWH8W6PRhCsqvYIdS//DD2WWayQR6slZtvLpM/OXAL502Xa/6fN8AJUs\neWb+L4D/+llHjUYTwTRpAqxfL8JXq1bl/DRmxo0LXb1CRb16knuorCw0EeeRMyNXo9GEJWb3jjsr\nP5IJdXplLfoajaZaSUqSVMmFhVr0Q4EWfY1GU62oqJzdu6NT9EO9epYWfY1GU60o0c/NdT8bN5LR\nlr5Go4kqlOjv2qUt/VCgRV+j0VQrSvT1QG5orqdFX6PRVCvm9ArRKPra0tdoNFFFkik1YzSKvrb0\nNRpNVNGwoTEpKRoHctU9a9HXaDRRAZGxMlU0W/ravaPRaKIG5dePZtHXlr5Go4katOhrS1+j0UQR\n0Sz6MTFA7dra0tdoNFGEiuCJxoFcILSrZ2nR12g01U40W/pAaFfPspVPv7opKSlBbm4uioqKqrsq\nmhpE7dq10apVK8THx1d3VTR+Eu2iH0pLPyxEPzc3Fw0aNEC7du1ARNVdHU0NgJlRUFCA3NxctG/f\nvrqro/GTaBf9UFr6YeHeKSoqQlJSkhZ8TQVEhKSkJN37ixCiXfS1T98CLfgaV/RvInLo1EkmabVq\nVd01qR60pa/RaKKKPn2AvXuBtLTqrkn1oEW/hlFQUIAePXqgR48eaN68OVJTUyu+FxcX2zrHxIkT\nsXnzZo9lXnrpJbz77ruBqLJGE3Y0bVrdNag+9EBuDSMpKQm//vorAODBBx9E/fr1MW3aNKcyzAxm\nRkyMdTv6xhtveL3OTTfd5H9lQ0xpaSni4vTPSKPxB23pe+LWW4EhQwL7uvXWKlVl69atSE9Px5VX\nXokuXbogPz8fkydPRmZmJrp06YKZM2dWlB04cCB+/fVXlJaWonHjxpg+fTq6d++OM888E/v27QMA\nzJgxA88++2xF+enTp6Nv3744/fTT8eOPPwIAjh8/jksuuQTp6ekYN24cMjMzKxokMw888AD69OmD\nrl274oYbbgAzAwBycnIwbNgwdO/eHb169cKOHTsAAP/617/QrVs3dO/eHffee69TnQFgz5496Nix\nIwDgtddew1/+8hcMHToU5557Lo4cOYJhw4ahV69eyMjIwOeff15RjzfeeAMZGRno3r07Jk6ciMLC\nQpx22mkoLS0FABw6dMjpu0YTjeiB3DDi999/x2233YaNGzciNTUVjz/+OLKyspCdnY1FixZh48aN\nlY4pLCzE4MGDkZ2djTPPPBNz5syxPDczY+XKlXjyyScrGpAXXngBzZs3x8aNG3Hfffdh7dq1lsf+\n4x//wKpVq7B+/XoUFhbi66+/BgBcfvnluO2225CdnY0ff/wRzZo1w8KFC/HVV19h5cqVyM7Oxh13\n3OH1vteuXYuPP/4YS5YsQZ06dfDpp59izZo1WLx4MW677TYAQHZ2Nv7973/j+++/R3Z2Np5++mk0\natQIAwYMqKjP+++/j7/+9a+6t6CJapSl77DNgkr4/U9zWMI1hQ4dOiAzM7Pi+/vvv4/XX38dpaWl\nyMvLw8aNG5Genu50TJ06dTB69GgAQO/evbF8+XLLc48dO7aijLLIV6xYgbvvvhsA0L17d3Tp0sXy\n2CVLluDJJ59EUVERDhw4gN69e6N///44cOAALrzwQgAyuQkAFi9ejGuvvRZ16tQBADQxL2XkhnPO\nOQeJjny4zIzp06djxYoViImJwa5du3DgwAF89913uPTSSyvOp96vu+46PP/887jgggvwxhtv4J13\n3vF6PY0mkqlXDygvB06dkjw8wST8RL+GUc+ULGTLli147rnnsHLlSjRu3BhXXXWVZRx5rVq1Kj7H\nxsa6dW0kJCR4LWPFiRMnMHXqVKxZswapqamYMWNGleLZ4+LiUF5eDgCVjjff99tvv43CwkKsWbMG\ncXFxaNWqlcfrDR48GFOnTsXSpUsRHx+Pzp07+1w3jSaSMKdXDrboa/dOADly5AgaNGiAhg0bIj8/\nH998803ArzFgwADMmzcPALB+/XpL99HJkycRExOD5ORkHD16FB999BEAIDExEU2bNsXChQsBiJCf\nOHECI0eOxJw5c3Dy5EkAwMGDBwEA7dq1w+rVqwEA8+fPd1unwsJCNGvWDHFxcVi0aBF2794NABg2\nbBg++OCDivOpdwC46qqrcOWVV2LixIl+PQ+NJhII5Tq5WvQDSK9evZCeno7OnTvjmmuuwYABAwJ+\njZtvvhm7d+9Geno6HnroIaSnp6NRo0ZOZZKSkvC3v/0N6enpGD16NPr161ex791338XTTz+NjIwM\nDBw4EPv378cFF1yAUaNGITMzEz169MB//vMfAMCdd96J5557Dr169cKhQ4fc1unqq6/Gjz/+iG7d\numHu3Lno1KkTAHE/3XXXXTj77LPRo0cP3HnnnRXHXHnllSgsLMSll14ayMej0YQlIV1IRYUaenoB\nGAVgM4CtAKZb7G8LYAmAdQC+B9DKtO9vALY4Xn/zdq3evXuzKxs3bqy0LVopKSnhkydPMjNzTk4O\nt2vXjktKSqq5Vr7z/vvv84QJE/w+j/5taCKBTz9lBphXr676OQBksQ099+rTJ6JYAC8BGAkgF8Aq\nIlrAzGa/wlMA3mbmt4hoGIDHAFxNRE0APAAgEwADWO041r3ZqPHIsWPHMHz4cJSWloKZMWvWrLCL\nfJkyZQoWL15cEcGj0UQ7obT07ahFXwBbmXkbABDRXABjAJhFPx3A7Y7PSwF86vh8LoBFzHzQcewi\nSK/hff+rHp00bty4ws8errz88svVXQWNpkYRStG349NPBbDL9D3Xsc1MNoCxjs8XA2hAREk2jwUR\nTSaiLCLK2r9/v926azQaTUQQjgO50wAMJqK1AAYD2A2gzO7BzDybmTOZObNpNCfg0Gg0UUlNc+/s\nBtDa9L2VY1sFzJwHh6VPRPUBXMLMh4loN4AhLsd+70d9NRqNJuKoaZb+KgCdiKg9EdUCcBmABeYC\nRJRMROpc9wBQeQW+AXAOESUSUSKAcxzbNBqNRuOgRvn0mbkUwFSIWG8CMI+ZNxDRTCK6yFFsCIDN\nRJQDIAXAo45jDwJ4GNJwrAIwUw3qhhNDhw6tNNHq2WefxZQpUzweV79+fQBAXl4exo0bZ1lmyJAh\nyMrK8nieZ599FidMv4bzzjsPhw8ftlN1jUYTBtQ0Sx/M/CUzpzFzB2ZWgn4/My9wfJ7PzJ0cZa5j\n5lOmY+cwc0fHy3t+4RrI5Zdfjrlz5zptmzt3Li6//HJbx7ds2dLjjFZvuIr+l19+icaNG1f5fKGG\nmSvSOWg0msrExwOxsTXE0q9pVEdm5XHjxuGLL76oWDBlx44dyMvLw6BBgyri5nv16oVu3brhs88+\nq3T8jh070LVrVwCSIuGyyy7DGWecgYsvvrgi9QEg8esqLfMDDzwAAHj++eeRl5eHoUOHYujQoQAk\nPcKBAwcAAM888wy6du2Krl27VqRl3rFjB8444wxMmjQJXbp0wTnnnON0HcXChQvRr18/9OzZEyNG\njMDevXsByFyAiRMnolu3bsjIyKhI4/D111+jV69e6N69O4YPHw5A1hd46qmnKs7ZtWtX7NixAzt2\n7MDpp5+Oa665Bl27dsWuXbss7w8AVq1ahbPOOgvdu3dH3759cfToUZx99tlOKaMHDhyI7Oxsz38o\njSZMIQpdeuXwmtVTTTRp0gR9+/bFV199hTFjxmDu3LkYP348iAi1a9fGJ598goYNG+LAgQPo378/\nLrroIrfrt7788suoW7cuNm3ahHXr1qFXr14V+x599FE0adIEZWVlGD58ONatW4dbbrkFzzzzDJYu\nXYrk5GSnc61evRpvvPEGfvnlFzAz+vXrh8GDByMxMRFbtmzB+++/j1dffRXjx4/HRx99hKuuusrp\n+IEDB+Lnn38GEeG1117DE088gaeffhoPP/wwGjVqhPXr1wOQnPf79+/HpEmTsGzZMrRv394pj447\ntmzZgrfeegv9+/d3e3+dO3fGpZdeig8++AB9+vTBkSNHUKdOHfz973/Hm2++iWeffRY5OTkoKipC\n9+7dffq7aTThRKgWUgk70a+uzMrKxaNE//XXXwcgrot//vOfWLZsGWJiYrB7927s3bsXzZs3tzzP\nsmXLcMsttwAAMjIykJGRUbFv3rx5mD17NkpLS5Gfn4+NGzc67XdlxYoVuPjiiysyXo4dOxbLly/H\nRRddhPbt26NHjx4AnFMzm8nNzcWll16K/Px8FBcXo3379gAk1bLZnZWYmIiFCxfi7LPPrihjJ/1y\n27ZtKwTf3f0REVq0aIE+ffoAABo2bAgA+Otf/4qHH34YTz75JObMmYMJEyZ4vZ5GE86ESvTDzr1T\nXYwZMwZLlizBmjVrcOLECfTu3RuAJDDbv38/Vq9ejV9//RUpKSlVSmO8fft2PPXUU1iyZAnWrVuH\n888/v0rnUai0zID71Mw333wzpk6divXr12PWrFl+p18GnFMwm9Mv+3p/devWxciRI/HZZ59h3rx5\nuPLKK32um0YTToTKvaNF3yb169fH0KFDce211zoN4Kq0wvHx8Vi6dCn+/PNPj+f5//buP7Sq+4zj\n+PtTa3rXzB9tJ2XLLauj/og/uMsPNWOLSLdA2o116ISpkAoNggztxqC0RMT90cJguB8oBWm3JWN2\nMludFCxsLuBfc8asplmTtbaWNTVVF9Ms6h9t2bM/zsnlmnqrZrk5ud/zvOCS+z33xPM8PNcn53zP\nueeuXr2a/fv3A9Db20tPTw8Q3Za5srKSOXPmcP78eY4ePZr/nVmzZjE6OvqJf6uxsZHDhw9z9epV\nrly5wqFDh2hsbLzpnEZGRqiqij4g3d7enl/e1NTE3r178+Ph4WEaGho4fvw4Z8+eBa69/XJ3dzcA\n3d3d+dfHK5bfokWLGBwc5OTJkwCMjo7m/0C1trayfft2VqxYkf/CFudC5Xv609CGDRs4ffr0NU1/\n06ZNdHV1sXz5cjo6Om74hSBbt27l8uXLVFdXs3PnzvwRQy6Xo6amhsWLF7Nx48Zrbsu8ZcsWmpub\n8ydyx9TW1rJ582ZWrlzJqlWraG1tpaam5qbz2bVrF+vXr6euru6a8wU7duxgeHiYZcuWkcvl6Ozs\nZN68eezbt4+1a9eSy+Xyt0Ret24dly5dYunSpezZs4eFCxded1vF8quoqODAgQNs27aNXC5HU1NT\n/gigrq6O2bNn+z33XSpM1Z6+bCq+lPEW1NfX2/jr1vv6+qiurk4oIpeUc+fOsWbNGvr7+7nttuvv\nn/h7w4Xi6aejpv/MMxP7fUmnzKz+RuuV3Ylclw4dHR20tbWxe/fuog3fuZC0tU3Ndrzpu2mppaWF\nlpaWpMNwLjhlsws13aahXPL8PeHcrSuLpp/JZBgaGvL/5C7PzBgaGiKTySQdinNlpSymd7LZLAMD\nA/gXrLhCmUyGbDabdBjOlZWyaPozZ87MfxLUOefcxJXF9I5zzrnJ4U3fOedSxJu+c86lyLT7RK6k\ni8Cn38Dm030O+PckhVMu0pgzpDPvNOYM6cz7VnP+opnNu9FK067p/78kdd3MR5FDksacIZ15pzFn\nSGfepcrZp3eccy5FvOk751yKhNj09yUdQALSmDOkM+805gzpzLskOQc3p++cc664EPf0nXPOFeFN\n3znnUiSYpi+pWdI/JZ2R9GTS8ZSKpPskdUp6XdI/JD0eL79b0p8kvRn/DO5LZSXNkPR3SS/H4/mS\nTsQ1PyCpIukYJ5ukuZIOSuqX1CfpK6HXWtIP4/d2r6QXJGVCrLWkX0m6IKm3YNl1a6vIL+P8eyTV\nTnS7QTR9STOAvcBDwBJgg6QlyUZVMh8DPzKzJUAD8P041yeBY2a2ADgWj0PzONBXMP4J8DMzewAY\nBh5LJKrS+gXwipktBnJE+Qdba0lVwHag3syWATOA7xFmrX8DNI9bVqy2DwEL4scW4NmJbjSIpg+s\nBM6Y2dtm9iHwe+CRhGMqCTMbNLPu+PkoUROoIsq3PV6tHfhOMhGWhqQs8E3guXgs4EHgYLxKiDnP\nAVYDzwOY2Ydm9gGB15ro7r+fkXQ7cCcwSIC1NrPjwKVxi4vV9hGgwyJ/BeZK+vxEthtK068C3i0Y\nD8TLgibpfqAGOAHca2aD8UvvA/cmFFap/Bx4AvhvPL4H+MDMPo7HIdZ8PnAR+HU8rfWcpEoCrrWZ\nvQf8FPgXUbMfAU4Rfq3HFKvtpPW4UJp+6kj6LPAi8AMz+0/haxZdhxvMtbiSvgVcMLNTSccyxW4H\naoFnzawGuMK4qZwAa30X0V7tfOALQCWfnAJJhVLVNpSm/x5wX8E4Gy8LkqSZRA3/d2b2Urz4/Njh\nXvzzQlLxlcBXgW9Leodo6u5BornuufEUAIRZ8wFgwMxOxOODRH8EQq71N4CzZnbRzD4CXiKqf+i1\nHlOstpPW40Jp+ieBBfEZ/gqiEz9HEo6pJOK57OeBPjPbXfDSEeDR+PmjwB+nOrZSMbOnzCxrZvcT\n1fYvZrYJ6AS+G68WVM4AZvY+8K6kRfGirwOvE3CtiaZ1GiTdGb/Xx3IOutYFitX2CNASX8XTAIwU\nTAPdGjML4gE8DLwBvAW0JR1PCfP8GtEhXw/wavx4mGiO+xjwJvBn4O6kYy1R/muAl+PnXwL+BpwB\n/gDckXR8Jcj3y0BXXO/DwF2h1xr4MdAP9AK/Be4IsdbAC0TnLT4iOqp7rFhtARFdofgW8BrR1U0T\n2q7fhsE551IklOkd55xzN8GbvnPOpYg3feecSxFv+s45lyLe9J1zLkW86TvnXIp403fOuRT5H94M\nZcptfWmWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}